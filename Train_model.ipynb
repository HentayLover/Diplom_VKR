{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Улучшенная модель из курсовой работы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Параметры\n",
    "NUM_POINTS = 5\n",
    "INPUT_SIZE = 4\n",
    "OUTPUT_SIZE = 4\n",
    "HIDDEN_SIZE = 256\n",
    "NUM_LAYERS = 4\n",
    "LEARNING_RATE = 0.001\n",
    "NUM_EPOCHS = 200\n",
    "BATCH_SIZE = 64\n",
    "MODEL_PATH = 'model_advanced/model.pth'\n",
    "ERROR_THRESHOLD = 0.1  # Порог для определения \"правильно предсказанных\" точек\n",
    "\n",
    "# Датасет\n",
    "class TrajectoryDataset(Dataset):\n",
    "    def __init__(self, directory):\n",
    "        self.data = []\n",
    "        self.load_data(directory)\n",
    "\n",
    "    def load_data(self, directory):\n",
    "        for filename in os.listdir(directory):\n",
    "            if filename.endswith('.txt'):\n",
    "                file_path = os.path.join(directory, filename)\n",
    "                trajectory = np.loadtxt(file_path)\n",
    "                for i in range(NUM_POINTS, len(trajectory)):\n",
    "                    input_data = trajectory[i - NUM_POINTS:i]\n",
    "                    output_data = trajectory[i - NUM_POINTS - 1]\n",
    "                    self.data.append((input_data, output_data))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.data[idx][0], dtype=torch.float32), torch.tensor(self.data[idx][1], dtype=torch.float32)\n",
    "\n",
    "# Улучшенная модель\n",
    "class AdvancedTrajectoryRNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AdvancedTrajectoryRNN, self).__init__()\n",
    "        # Входная проекция\n",
    "        self.input_projection = nn.Sequential(\n",
    "            nn.Linear(INPUT_SIZE, HIDDEN_SIZE // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(HIDDEN_SIZE // 2, HIDDEN_SIZE),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # Рекуррентный блок\n",
    "        self.lstm = nn.LSTM(HIDDEN_SIZE, HIDDEN_SIZE, NUM_LAYERS, batch_first=True, dropout=0.4)\n",
    "        \n",
    "        # Глобальный механизм внимания\n",
    "        self.attention = nn.Linear(HIDDEN_SIZE, HIDDEN_SIZE)\n",
    "        self.attention_context = nn.Parameter(torch.randn(HIDDEN_SIZE))\n",
    "        \n",
    "        # Batch Normalization и проекции\n",
    "        self.batch_norm = nn.BatchNorm1d(HIDDEN_SIZE)\n",
    "        self.residual_connection = nn.Linear(HIDDEN_SIZE, HIDDEN_SIZE)\n",
    "        \n",
    "        # Выходной слой\n",
    "        self.output_layers = nn.Sequential(\n",
    "            nn.Linear(HIDDEN_SIZE, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(128, OUTPUT_SIZE)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Входная проекция\n",
    "        x_proj = self.input_projection(x)  # (batch_size, NUM_POINTS, HIDDEN_SIZE)\n",
    "        \n",
    "        # LSTM\n",
    "        lstm_out, _ = self.lstm(x_proj)  # (batch_size, NUM_POINTS, HIDDEN_SIZE)\n",
    "        \n",
    "        # Механизм внимания\n",
    "        attention_weights = torch.tanh(self.attention(lstm_out))  # (batch_size, NUM_POINTS, HIDDEN_SIZE)\n",
    "        attention_weights = torch.matmul(attention_weights, self.attention_context)  # (batch_size, NUM_POINTS)\n",
    "        attention_weights = torch.softmax(attention_weights, dim=1)  # (batch_size, NUM_POINTS)\n",
    "        context_vector = torch.sum(lstm_out * attention_weights.unsqueeze(-1), dim=1)  # (batch_size, HIDDEN_SIZE)\n",
    "        \n",
    "        # BatchNorm\n",
    "        normalized_out = self.batch_norm(context_vector)\n",
    "        \n",
    "        # Остаточная связь\n",
    "        residual_out = normalized_out + self.residual_connection(normalized_out)\n",
    "        \n",
    "        # Выходной слой\n",
    "        output = self.output_layers(residual_out)\n",
    "        return output\n",
    "\n",
    "# Функции для вычисления ошибок\n",
    "def compute_mse(outputs, targets):\n",
    "    return torch.mean((outputs - targets) ** 2)\n",
    "\n",
    "def compute_mae(outputs, targets):\n",
    "    return torch.mean(torch.abs(outputs - targets))\n",
    "\n",
    "def compute_med(outputs, targets):\n",
    "    # Евклидово расстояние (MED) между предсказанием и истинной точкой\n",
    "    distance = torch.norm(outputs - targets, dim=1)\n",
    "    return torch.mean(distance)\n",
    "\n",
    "def compute_accuracy(outputs, targets, error_threshold=ERROR_THRESHOLD):\n",
    "    # Евклидово расстояние (MED) между предсказанием и истинной точкой\n",
    "    distance = torch.norm(outputs - targets, dim=1)\n",
    "    # Если расстояние меньше порога, считаем точку предсказанную правильно\n",
    "    correct_predictions = (distance < error_threshold).float()\n",
    "    accuracy = correct_predictions.mean().item()\n",
    "    return accuracy\n",
    "\n",
    "# Основная функция\n",
    "def main(directory):\n",
    "    os.makedirs('model_advanced', exist_ok=True)\n",
    "\n",
    "    dataset = TrajectoryDataset(directory)\n",
    "    dataset_size = len(dataset)\n",
    "    val_size = int(0.2 * dataset_size)  # 20% данных на валидацию\n",
    "    train_size = dataset_size - val_size\n",
    "\n",
    "    # Разделение на обучающую и валидационную выборки\n",
    "    train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    val_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "    model = AdvancedTrajectoryRNN()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    best_loss = float('inf')\n",
    "    epoch_losses = []\n",
    "    val_losses = []\n",
    "    train_mse = []\n",
    "    val_mse = []\n",
    "    train_mae = []\n",
    "    val_mae = []\n",
    "    train_med = []\n",
    "    val_med = []\n",
    "    train_accuracy = []\n",
    "    val_accuracy = []\n",
    "\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        model.train()\n",
    "        epoch_loss = 0.0\n",
    "        epoch_mse = 0.0\n",
    "        epoch_mae = 0.0\n",
    "        epoch_med = 0.0\n",
    "        epoch_accuracy = 0.0\n",
    "        for inputs, targets in train_dataloader:\n",
    "            inputs = inputs.view(-1, NUM_POINTS, INPUT_SIZE)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "            # Вычисляем метрики\n",
    "            mse = compute_mse(outputs, targets)\n",
    "            mae = compute_mae(outputs, targets)\n",
    "            med = compute_med(outputs, targets)\n",
    "            accuracy = compute_accuracy(outputs, targets, ERROR_THRESHOLD)\n",
    "\n",
    "            epoch_mse += mse.item()\n",
    "            epoch_mae += mae.item()\n",
    "            epoch_med += med.item()\n",
    "            epoch_accuracy += accuracy\n",
    "\n",
    "        average_loss = epoch_loss / len(train_dataloader)\n",
    "        average_mse = epoch_mse / len(train_dataloader)\n",
    "        average_mae = epoch_mae / len(train_dataloader)\n",
    "        average_med = epoch_med / len(train_dataloader)\n",
    "        average_accuracy = epoch_accuracy / len(train_dataloader)\n",
    "\n",
    "        epoch_losses.append(average_loss)\n",
    "        train_mse.append(average_mse)\n",
    "        train_mae.append(average_mae)\n",
    "        train_med.append(average_med)\n",
    "        train_accuracy.append(average_accuracy)\n",
    "\n",
    "        # Валидация\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_mse_val = 0.0\n",
    "        val_mae_val = 0.0\n",
    "        val_med_val = 0.0\n",
    "        val_accuracy_val = 0.0\n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in val_dataloader:\n",
    "                inputs = inputs.view(-1, NUM_POINTS, INPUT_SIZE)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                # Вычисляем метрики\n",
    "                mse = compute_mse(outputs, targets)\n",
    "                mae = compute_mae(outputs, targets)\n",
    "                med = compute_med(outputs, targets)\n",
    "                accuracy = compute_accuracy(outputs, targets, ERROR_THRESHOLD)\n",
    "\n",
    "                val_mse_val += mse.item()\n",
    "                val_mae_val += mae.item()\n",
    "                val_med_val += med.item()\n",
    "                val_accuracy_val += accuracy\n",
    "\n",
    "        average_val_loss = val_loss / len(val_dataloader)\n",
    "        average_val_mse = val_mse_val / len(val_dataloader)\n",
    "        average_val_mae = val_mae_val / len(val_dataloader)\n",
    "        average_val_med = val_med_val / len(val_dataloader)\n",
    "        average_val_accuracy = val_accuracy_val / len(val_dataloader)\n",
    "\n",
    "        val_losses.append(average_val_loss)\n",
    "        val_mse.append(average_val_mse)\n",
    "        val_mae.append(average_val_mae)\n",
    "        val_med.append(average_val_med)\n",
    "        val_accuracy.append(average_val_accuracy)\n",
    "\n",
    "        # Сохраняем модель, если потеря на валидации улучшилась\n",
    "        if average_val_loss < best_loss:\n",
    "            best_loss = average_val_loss\n",
    "            torch.save(model.state_dict(), MODEL_PATH)\n",
    "\n",
    "            print(f'Модель сохранена на эпохе {epoch + 1} с потерей {average_val_loss:.4f}')\n",
    "            print(f'Модель сохранена по пути: {os.path.abspath(MODEL_PATH)}')  # Путь сохраненной модели\n",
    "\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f'Epoch [{epoch + 1}/{NUM_EPOCHS}], Train Loss: {average_loss:.4f}, Train MSE: {average_mse:.4f}, Train MAE: {average_mae:.4f}, Train MED: {average_med:.4f}, Train Accuracy: {average_accuracy:.4f}, Val Loss: {average_val_loss:.4f}, Val MSE: {average_val_mse:.4f}, Val MAE: {average_val_mae:.4f}, Val MED: {average_val_med:.4f}, Val Accuracy: {average_val_accuracy:.4f}')\n",
    "\n",
    "    print('Обучение завершено!')\n",
    "\n",
    "    # Визуализация\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(range(1, NUM_EPOCHS + 1), epoch_losses, label='Train Loss', color='blue')\n",
    "    plt.plot(range(1, NUM_EPOCHS + 1), val_losses, label='Validation Loss', color='orange')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training and Validation Loss Over Epochs')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.savefig('loss_plot.png')\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(range(1, NUM_EPOCHS + 1), train_mse, label='Train MSE', color='blue')\n",
    "    plt.plot(range(1, NUM_EPOCHS + 1), val_mse, label='Validation MSE', color='orange')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('MSE')\n",
    "    plt.title('Training and Validation MSE Over Epochs')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.savefig('mse_plot.png')\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(range(1, NUM_EPOCHS + 1), train_mae, label='Train MAE', color='blue')\n",
    "    plt.plot(range(1, NUM_EPOCHS + 1), val_mae, label='Validation MAE', color='orange')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('MAE')\n",
    "    plt.title('Training and Validation MAE Over Epochs')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.savefig('mae_plot.png')\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(range(1, NUM_EPOCHS + 1), train_med, label='Train MED', color='blue')\n",
    "    plt.plot(range(1, NUM_EPOCHS + 1), val_med, label='Validation MED', color='orange')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('MED')\n",
    "    plt.title('Training and Validation MED Over Epochs')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.savefig('med_plot.png')\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(range(1, NUM_EPOCHS + 1), train_accuracy, label='Train Accuracy', color='blue')\n",
    "    plt.plot(range(1, NUM_EPOCHS + 1), val_accuracy, label='Validation Accuracy', color='orange')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Training and Validation Accuracy Over Epochs')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.savefig('accuracy_plot.png')\n",
    "    plt.show()\n",
    "\n",
    "# Запуск\n",
    "if __name__ == \"__main__\":\n",
    "    data_directory = 'New_traectory_norm'\n",
    "    main(data_directory)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Изменен тип сохранений. Теперь сохраняется на основании лучшей Val accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Модель сохранена на эпохе 1 с точностью 0.7218\n",
      "Модель сохранена по пути: c:\\Users\\PC1\\Desktop\\Диплом\\git_folder\\Diplom_VKR\\model_advanced\\model_ver2.pth\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Параметры\n",
    "NUM_POINTS = 5\n",
    "INPUT_SIZE = 4\n",
    "OUTPUT_SIZE = 4\n",
    "HIDDEN_SIZE = 256\n",
    "NUM_LAYERS = 4\n",
    "LEARNING_RATE = 0.001\n",
    "NUM_EPOCHS = 200\n",
    "BATCH_SIZE = 64\n",
    "MODEL_PATH = 'model_advanced/model_ver2.pth'\n",
    "ERROR_THRESHOLD = 0.1  # Порог для определения \"правильно предсказанных\" точек\n",
    "\n",
    "# Датасет\n",
    "class TrajectoryDataset(Dataset):\n",
    "    def __init__(self, directory):\n",
    "        self.data = []\n",
    "        self.load_data(directory)\n",
    "\n",
    "    def load_data(self, directory):\n",
    "        for filename in os.listdir(directory):\n",
    "            if filename.endswith('.txt'):\n",
    "                file_path = os.path.join(directory, filename)\n",
    "                trajectory = np.loadtxt(file_path)\n",
    "                for i in range(NUM_POINTS, len(trajectory)):\n",
    "                    input_data = trajectory[i - NUM_POINTS:i]\n",
    "                    output_data = trajectory[i - NUM_POINTS - 1]\n",
    "                    self.data.append((input_data, output_data))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.data[idx][0], dtype=torch.float32), torch.tensor(self.data[idx][1], dtype=torch.float32)\n",
    "\n",
    "# Улучшенная модель\n",
    "class AdvancedTrajectoryRNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AdvancedTrajectoryRNN, self).__init__()\n",
    "        # Входная проекция\n",
    "        self.input_projection = nn.Sequential(\n",
    "            nn.Linear(INPUT_SIZE, HIDDEN_SIZE // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(HIDDEN_SIZE // 2, HIDDEN_SIZE),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        # Рекуррентный блок\n",
    "        self.lstm = nn.LSTM(HIDDEN_SIZE, HIDDEN_SIZE, NUM_LAYERS, batch_first=True, dropout=0.4)\n",
    "        \n",
    "        # Глобальный механизм внимания\n",
    "        self.attention = nn.Linear(HIDDEN_SIZE, HIDDEN_SIZE)\n",
    "        self.attention_context = nn.Parameter(torch.randn(HIDDEN_SIZE))\n",
    "        \n",
    "        # Batch Normalization и проекции\n",
    "        self.batch_norm = nn.BatchNorm1d(HIDDEN_SIZE)\n",
    "        self.residual_connection = nn.Linear(HIDDEN_SIZE, HIDDEN_SIZE)\n",
    "        \n",
    "        # Выходной слой\n",
    "        self.output_layers = nn.Sequential(\n",
    "            nn.Linear(HIDDEN_SIZE, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(128, OUTPUT_SIZE)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Входная проекция\n",
    "        x_proj = self.input_projection(x)  # (batch_size, NUM_POINTS, HIDDEN_SIZE)\n",
    "        \n",
    "        # LSTM\n",
    "        lstm_out, _ = self.lstm(x_proj)  # (batch_size, NUM_POINTS, HIDDEN_SIZE)\n",
    "        \n",
    "        # Механизм внимания\n",
    "        attention_weights = torch.tanh(self.attention(lstm_out))  # (batch_size, NUM_POINTS, HIDDEN_SIZE)\n",
    "        attention_weights = torch.matmul(attention_weights, self.attention_context)  # (batch_size, NUM_POINTS)\n",
    "        attention_weights = torch.softmax(attention_weights, dim=1)  # (batch_size, NUM_POINTS)\n",
    "        context_vector = torch.sum(lstm_out * attention_weights.unsqueeze(-1), dim=1)  # (batch_size, HIDDEN_SIZE)\n",
    "        \n",
    "        # BatchNorm\n",
    "        normalized_out = self.batch_norm(context_vector)\n",
    "        \n",
    "        # Остаточная связь\n",
    "        residual_out = normalized_out + self.residual_connection(normalized_out)\n",
    "        \n",
    "        # Выходной слой\n",
    "        output = self.output_layers(residual_out)\n",
    "        return output\n",
    "\n",
    "# Функции для вычисления ошибок\n",
    "def compute_mse(outputs, targets):\n",
    "    return torch.mean((outputs - targets) ** 2)\n",
    "\n",
    "def compute_mae(outputs, targets):\n",
    "    return torch.mean(torch.abs(outputs - targets))\n",
    "\n",
    "def compute_med(outputs, targets):\n",
    "    # Евклидово расстояние (MED) между предсказанием и истинной точкой\n",
    "    distance = torch.norm(outputs - targets, dim=1)\n",
    "    return torch.mean(distance)\n",
    "\n",
    "def compute_accuracy(outputs, targets, error_threshold=ERROR_THRESHOLD):\n",
    "    # Евклидово расстояние (MED) между предсказанием и истинной точкой\n",
    "    distance = torch.norm(outputs - targets, dim=1)\n",
    "    # Если расстояние меньше порога, считаем точку предсказанную правильно\n",
    "    correct_predictions = (distance < error_threshold).float()\n",
    "    accuracy = correct_predictions.mean().item()\n",
    "    return accuracy\n",
    "\n",
    "# Основная функция\n",
    "def main(directory):\n",
    "    os.makedirs('model_advanced', exist_ok=True)\n",
    "\n",
    "    dataset = TrajectoryDataset(directory)\n",
    "    dataset_size = len(dataset)\n",
    "    val_size = int(0.2 * dataset_size)  # 20% данных на валидацию\n",
    "    train_size = dataset_size - val_size\n",
    "\n",
    "    # Разделение на обучающую и валидационную выборки\n",
    "    train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    val_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "    model = AdvancedTrajectoryRNN()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    best_val_accuracy = -1  # Изначально устанавливаем отрицательное значение\n",
    "\n",
    "    epoch_losses = []\n",
    "    val_losses = []\n",
    "    train_accuracy = []\n",
    "    val_accuracy = []\n",
    "\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        model.train()\n",
    "        epoch_loss = 0.0\n",
    "        epoch_accuracy = 0.0\n",
    "        for inputs, targets in train_dataloader:\n",
    "            inputs = inputs.view(-1, NUM_POINTS, INPUT_SIZE)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "            # Вычисляем метрики\n",
    "            accuracy = compute_accuracy(outputs, targets, ERROR_THRESHOLD)\n",
    "            epoch_accuracy += accuracy\n",
    "\n",
    "        average_loss = epoch_loss / len(train_dataloader)\n",
    "        average_accuracy = epoch_accuracy / len(train_dataloader)\n",
    "\n",
    "        epoch_losses.append(average_loss)\n",
    "        train_accuracy.append(average_accuracy)\n",
    "\n",
    "        # Валидация\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_accuracy_val = 0.0\n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in val_dataloader:\n",
    "                inputs = inputs.view(-1, NUM_POINTS, INPUT_SIZE)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                # Вычисляем метрики\n",
    "                accuracy = compute_accuracy(outputs, targets, ERROR_THRESHOLD)\n",
    "                val_accuracy_val += accuracy\n",
    "\n",
    "        average_val_loss = val_loss / len(val_dataloader)\n",
    "        average_val_accuracy = val_accuracy_val / len(val_dataloader)\n",
    "\n",
    "        val_losses.append(average_val_loss)\n",
    "        val_accuracy.append(average_val_accuracy)\n",
    "\n",
    "        # Сохраняем модель, если точность на валидации улучшилась\n",
    "        if average_val_accuracy > best_val_accuracy:\n",
    "            best_val_accuracy = average_val_accuracy\n",
    "            torch.save(model.state_dict(), MODEL_PATH)\n",
    "\n",
    "            print(f'Модель сохранена на эпохе {epoch + 1} с точностью {average_val_accuracy:.4f}')\n",
    "            print(f'Модель сохранена по пути: {os.path.abspath(MODEL_PATH)}')  # Путь сохраненной модели\n",
    "\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f'Epoch [{epoch + 1}/{NUM_EPOCHS}], Train Loss: {average_loss:.4f}, Train Accuracy: {average_accuracy:.4f}, Val Loss: {average_val_loss:.4f}, Val Accuracy: {average_val_accuracy:.4f}')\n",
    "\n",
    "    print('Обучение завершено!')\n",
    "\n",
    "    # Визуализация\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(range(1, NUM_EPOCHS + 1), epoch_losses, label='Train Loss', color='blue')\n",
    "    plt.plot(range(1, NUM_EPOCHS + 1), val_losses, label='Validation Loss', color='orange')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training and Validation Loss Over Epochs')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.savefig('loss_plot.png')\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(range(1, NUM_EPOCHS + 1), train_accuracy, label='Train Accuracy', color='blue')\n",
    "    plt.plot(range(1, NUM_EPOCHS + 1), val_accuracy, label='Validation Accuracy', color='orange')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Training and Validation Accuracy Over Epochs')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.savefig('accuracy_plot.png')\n",
    "    plt.show()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    data_directory = 'New_traectory_norm'\n",
    "    main(data_directory)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
